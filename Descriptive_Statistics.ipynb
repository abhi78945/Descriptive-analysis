{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN+vMMVvmrFSM9hkpvkICFp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi78945/Descriptive-analysis/blob/main/Descriptive_Statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Customer Purchase Behavior Analysis using Descriptive Statistics\n",
        "##Problem Statement\n",
        "\n",
        "üîç Problem Statement:\n",
        "\n",
        "Welcome to the Probability and Statistics project! üìäüîç In this exciting journey, you'll get the chance to apply the concepts you've learned in probability theory and statistics to analyze a real-world dataset. This project is your opportunity to dive deep into the world of data analysis and gain practical experience with the tools and techniques you've been learning. üöÄ\n",
        "\n",
        "üéØ Objective:\n",
        "\n",
        "Your mission is to analyze the provided dataset containing customer information and purchasing behavior to make informed decisions. Your goal is to identify patterns, trends, and correlations that will help your company optimize its marketing efforts and increase offer acceptance rates. üéâ\n",
        "\n",
        "##About the Dataset\n",
        "\n",
        "Here's the link to the dataset\n",
        "\n",
        "This data was gathered during last year's campaign. Data description is as follows;\n",
        "\n",
        "Response (target) - 1 if customer accepted the offer in the last campaign, 0 otherwise\n",
        "ID - Unique ID of each customer\n",
        "Year_Birth - Age of the customer\n",
        "Complain - 1 if the customer complained in the last 2 years\n",
        "Dt_Customer - date of customer's enrollment with the company\n",
        "Education - customer's level of education\n",
        "Marital - customer's marital status\n",
        "Kidhome - number of small children in customer's household\n",
        "Teenhome - number of teenagers in customer's household\n",
        "Income - customer's yearly household income\n",
        "MntFishProducts - the amount spent on fish products in the last 2 years\n",
        "MntMeatProducts - the amount spent on meat products in the last 2 years\n",
        "MntFruits - the amount spent on fruits products in the last 2 years\n",
        "MntSweetProducts - amount spent on sweet products in the last 2 years\n",
        "MntWines - the amount spent on wine products in the last 2 years\n",
        "MntGoldProds - the amount spent on gold products in the last 2 years\n",
        "NumDealsPurchases - number of purchases made with discount\n",
        "NumCatalogPurchases - number of purchases made using catalog (buying goods to be shipped through the mail)\n",
        "NumStorePurchases - number of purchases made directly in stores\n",
        "NumWebPurchases - number of purchases made through the company's website\n",
        "NumWebVisitsMonth - number of visits to company's website in the last month\n",
        "Recency - number of days since the last purchase\n",
        "##Task 1 - Basic CleanUp\n",
        "\n",
        "Clean and preprocess the dataset (handling missing values, data types, etc.).\n",
        "\n",
        "Analyze the distribution of customer demographics (age, education, marital status) using descriptive statistics and visualizations.\n",
        "\n",
        "Deliverables:\n",
        "\n",
        "Cleaned and Preprocessed Dataset:\n",
        "\n",
        "Provide a detailed report on the steps taken to handle missing values, including imputation methods used if applicable. Document the process of ensuring consistent data types for each variable, addressing any inconsistencies.\n",
        "\n",
        "Summary of Basic Statistics:\n",
        "\n",
        "Present calculated statistics such as mean, median, variance, and standard deviation for each relevant numerical variable. Include a concise table or summary showcasing these measures for easy reference."
      ],
      "metadata": {
        "id": "1VYDUQ-UbYL7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR7w31zDHMYI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the csv dataset\n",
        "dfs = pd.read_csv(\"/content/Superstore Marketing Data - Sheet1 (1).csv\")"
      ],
      "metadata": {
        "id": "mOe6hFFVHlLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs.head()"
      ],
      "metadata": {
        "id": "C_O9b1UcIP-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#basic info about our data\n",
        "dfs.info()"
      ],
      "metadata": {
        "id": "OW9un7RsIbi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs.shape"
      ],
      "metadata": {
        "id": "adJzI6mvH04r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dfs.apply(lambda col:col.unique()))"
      ],
      "metadata": {
        "id": "Ck28MU_iH5Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting number of unwanated string in the column\n",
        "dt_cust =  dfs['Dt_Customer'] == '########'\n",
        "print(dt_cust.sum())"
      ],
      "metadata": {
        "id": "bUtGNPi4IA9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replacing string with NA value to calculate amount of null values in the dataset\n",
        "dfs['Dt_Customer'] = dfs['Dt_Customer'].replace('########', pd.NA)"
      ],
      "metadata": {
        "id": "PUIzY4kLIN12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the num of nulls in each column\n",
        "dfs.isnull().sum()"
      ],
      "metadata": {
        "id": "8U-AOK5pLlNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of null values in each column\n",
        "null_percentage = (dfs.isnull().sum() / len(dfs)) * 100\n",
        "\n",
        "# Create a new DataFrame to display the null percentage for each column\n",
        "null_percentage_df = pd.DataFrame({'NullPercentage': null_percentage})\n",
        "\n",
        "# Display the null percentage for each column\n",
        "null_percentage_df"
      ],
      "metadata": {
        "id": "erudyiBqKCCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs['Dt_Customer'] = pd.to_datetime(dfs['Dt_Customer'])"
      ],
      "metadata": {
        "id": "vRS8HnftKaDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the column 'Dt_Customer' has 40% missing data, which is the date has not been updated since year 2014, so I will drop the column as the major chunk of the data is missing."
      ],
      "metadata": {
        "id": "y2vxCqhlKo3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs.drop(columns='Dt_Customer', inplace=True)"
      ],
      "metadata": {
        "id": "Bq5iv3y7KqnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analyzing Income column"
      ],
      "metadata": {
        "id": "msDGyMMYLA1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs.describe()"
      ],
      "metadata": {
        "id": "QTbukWvdLGSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that the 'Income' column has 1% missing value, so I'll be filling it with median value."
      ],
      "metadata": {
        "id": "SqEKfL_nMI7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling missing value with median value\n",
        "median_income = dfs['Income'].median()\n",
        "dfs['Income'].fillna(median_income, inplace=True)"
      ],
      "metadata": {
        "id": "Qndh8A8iMK1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a boxplot for 'Income' column\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot(dfs['Income'], vert=False)\n",
        "plt.title('Boxplot of Income')\n",
        "plt.xlabel('Income')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FE0rHPRSNU0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs.describe()"
      ],
      "metadata": {
        "id": "GMeIr9VaNfUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing extreme outliers (e.g., values beyond 3 standard deviations)\n",
        "std_dev = dfs['Income'].std()\n",
        "mean_income = dfs['Income'].mean()\n",
        "df = dfs[(dfs['Income'] >= mean_income - 3 * std_dev) & (dfs['Income'] <= mean_income + 3 * std_dev)]"
      ],
      "metadata": {
        "id": "0TXc1JMVNxCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a boxplot for 'Income' column\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot(dfs['Income'], vert=False)\n",
        "plt.title('Boxplot of Income')\n",
        "plt.xlabel('Income')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mwF0GakvOfhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical variables - Calculating basic statistics (mean, median, variance, standard deviation)\n",
        "numerical_cols = ['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits',\n",
        "                  'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
        "                  'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',\n",
        "                  'NumWebVisitsMonth']\n",
        "numerical_stats = dfs[numerical_cols].describe()\n",
        "\n",
        "# Categorical variables - Calculating frequency counts or percentages\n",
        "categorical_cols = ['Education', 'Marital_Status', 'Response', 'Complain']\n",
        "categorical_stats = {}\n",
        "for col in categorical_cols:\n",
        "    categorical_stats[col] = dfs[col].value_counts(normalize=True) * 100  # Calculate percentages\n",
        "\n",
        "# Displaying the calculated statistics\n",
        "print(\"Basic Statistics for Numerical Variables:\")\n",
        "print(numerical_stats)\n",
        "\n",
        "print(\"\\nFrequency Counts or Percentages for Categorical Variables:\")\n",
        "for col, values in categorical_stats.items():\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(values)"
      ],
      "metadata": {
        "id": "yWeAVRzwPZ3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the distribution of customer demographics including age, education, and marital status using histograms and bar charts"
      ],
      "metadata": {
        "id": "3g_Td9QfP32l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Age distribution using a histogram\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(dfs['Year_Birth'], bins=30, kde=True, color='skyblue')\n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Year of Birth')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Visualization of Education and Marital Status using bar charts\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Education distribution\n",
        "plt.subplot(1, 2, 1)\n",
        "education_counts = dfs['Education'].value_counts()\n",
        "sns.barplot(x=education_counts.index, y=education_counts.values, palette='viridis')\n",
        "plt.title('Education Distribution')\n",
        "plt.xlabel('Education Level')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Marital Status distribution\n",
        "plt.subplot(1, 2, 2)\n",
        "marital_counts = dfs['Marital_Status'].value_counts()\n",
        "sns.barplot(x=marital_counts.index, y=marital_counts.values, palette='muted')\n",
        "plt.title('Marital Status Distribution')\n",
        "plt.xlabel('Marital Status')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iTGnPTIbPxFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analysis of Customer Demographics\n",
        "**Age Distribution (Histogram)**\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "The histogram represents the distribution of customer ages based on birth year.\n",
        "Provides an overview of age spread and concentration within the dataset.\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "The distribution appears to be relatively normal or slightly right-skewed.\n",
        "Dominant customer segments within specific age ranges might be identifiable.\n",
        "\n",
        "**Education Distribution (Bar Chart)**\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "The bar chart displays the frequency of customers in different education levels.\n",
        "Visualizes the relative proportions of customers across educational backgrounds.\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "Graduated custoers prevalent highest education levels among customers based on the tallest bars.\n",
        "Shows the diversity in educational backgrounds within the customer base.\n",
        "\n",
        "**Marital Status Distribution (Bar Chart)**\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "The bar chart illustrates the distribution of customers across various marital statuses.\n",
        "Helps in understanding the prevalence of different marital statuses among customers.\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "Highlights the dominant marital status category among the customer base are the married people.\n",
        "Provides insights into the relative distribution across different marital statuses.\n",
        "\n",
        "**Overall Insights and Actionable Points**\n",
        "\n",
        "**Understanding Customer Demographics:**\n",
        "\n",
        "Helps in targeted marketing strategies based on age groups, educational backgrounds, and marital statuses.\n",
        "\n",
        "**Tailored Marketing and Offers:**\n",
        "\n",
        "Customizing campaigns or products to match the preferences of specific demographic segments identified."
      ],
      "metadata": {
        "id": "DYoBan-RQr8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 2 - Descriptive Statistics üìä\n",
        "Calculate measures of central tendency (mean, median, mode) and measures of dispersion (variance, standard deviation) for key variables. Identify and handle outliers if necessary.\n",
        "\n",
        "**Deliverables:**\n",
        "\n",
        "Descriptive statistics that reveal the central tendencies, variations, and potential outliers in the dataset.:"
      ],
      "metadata": {
        "id": "QSLQscXhTJfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting relevant numerical columns\n",
        "numerical_cols = ['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits',\n",
        "                  'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
        "                  'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',\n",
        "                  'NumWebVisitsMonth']\n",
        "\n",
        "# Calculating statistics for numerical columns\n",
        "numerical_stats = dfs[numerical_cols].agg(['mean', 'median', 'var', 'std']).transpose()\n",
        "\n",
        "# Renaming index and formatting the table\n",
        "numerical_stats.index.name = 'Numerical Variables'\n",
        "numerical_stats.columns = ['Mean', 'Median', 'Variance', 'Standard Deviation']\n",
        "\n",
        "# Displaying the summary table\n",
        "numerical_stats"
      ],
      "metadata": {
        "id": "6b49jcvnTh8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns\n",
        "columns_to_visualize = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
        "                        'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases',\n",
        "                        'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',\n",
        "                        'NumWebVisitsMonth']\n",
        "\n",
        "# Create boxplots for outlier detection\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Loop through columns to create boxplots\n",
        "for i, column in enumerate(columns_to_visualize, start=1):\n",
        "    plt.subplot(3, 4, i)\n",
        "    plt.boxplot(df[column].dropna(), vert=False)\n",
        "    plt.title(column)\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "He5FpcRdT3N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Handling Outliers**"
      ],
      "metadata": {
        "id": "FqhuCcChULw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in columns_to_visualize:\n",
        "    Q1 = dfs[column].quantile(0.25)\n",
        "    Q3 = dfs[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Use .loc to modify the DataFrame explicitly\n",
        "    dfs.loc[dfs[column] < lower_bound, column] = lower_bound\n",
        "    dfs.loc[dfs[column] > upper_bound, column] = upper_bound"
      ],
      "metadata": {
        "id": "xuXcriapUaZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns\n",
        "columns_to_visualize = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
        "                        'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases',\n",
        "                        'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',\n",
        "                        'NumWebVisitsMonth']\n",
        "\n",
        "# Create boxplots for outlier detection\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Loop through columns to create boxplots\n",
        "for i, column in enumerate(columns_to_visualize, start=1):\n",
        "    plt.subplot(3, 4, i)\n",
        "    plt.boxplot(dfs[column].dropna(), vert=False)\n",
        "    plt.title(column)\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1l4VJ1bkVCnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Discriptive Statistics after handling outliers"
      ],
      "metadata": {
        "id": "EWwu_Q62VpMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting relevant numerical columns\n",
        "numerical_cols = ['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits',\n",
        "                  'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
        "                  'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',\n",
        "                  'NumWebVisitsMonth']\n",
        "\n",
        "# Calculating statistics for numerical columns\n",
        "numerical_stats = dfs[numerical_cols].agg(['mean', 'median', 'var', 'std']).transpose()\n",
        "\n",
        "# Renaming index and formatting the table\n",
        "numerical_stats.index.name = 'Numerical Variables'\n",
        "numerical_stats.columns = ['Mean', 'Median', 'Variance', 'Standard Deviation']\n",
        "\n",
        "# Displaying the summary table\n",
        "numerical_stats\n"
      ],
      "metadata": {
        "id": "NNgSe-lTVSX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 3 - Probability Distributions üé≤\n",
        "Identify variables that could follow specific probability distributions (e.g., Binomial, Normal). Calculate probabilities and expected values based on these distributions.\n",
        "\n",
        "**Deliverables:**\n",
        "\n",
        "Determination of suitable probability distributions for relevant variables and corresponding calculated probabilities and expected values.:"
      ],
      "metadata": {
        "id": "Xt8NayPiWHYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Response' is a binary variable (0: No response, 1: Response)\n",
        "# Calculate the probability of a response (success) based on the dataset\n",
        "prob_response = dfs['Response'].mean()  # Probability of success (response)\n",
        "\n",
        "# Probability Mass Function (PMF) for Bernoulli distribution (probability of success = prob_response)\n",
        "prob_success = stats.bernoulli.pmf(1, prob_response)\n",
        "print(f\"Probability of Response = 1 (success): {prob_success:.4f}\")\n",
        "\n",
        "# Expected value (mean) for a Bernoulli distribution\n",
        "expected_value = stats.bernoulli.mean(prob_response)\n",
        "print(f\"Expected value (mean) for Response: {expected_value:.4f}\")\n",
        "\n",
        "# Visualize Bernoulli distribution\n",
        "x = [0, 1]  # Possible outcomes for a Bernoulli distribution\n",
        "pmf_values = stats.bernoulli.pmf(x, prob_response)\n",
        "\n",
        "plt.bar(x, pmf_values, align='center', alpha=0.5)\n",
        "plt.xticks(x)\n",
        "plt.xlabel('Response')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Bernoulli Distribution for Response')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vS_Z7AIZWkqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Complain' is a binary variable (0: No complaint, 1: Complaint)\n",
        "# Calculate the probability of a complaint (success) based on the dataset\n",
        "prob_complain = dfs['Complain'].mean()  # Probability of success (complaint)\n",
        "\n",
        "# Probability Mass Function (PMF) for Bernoulli distribution (probability of success = prob_complain)\n",
        "prob_success = stats.bernoulli.pmf(1, prob_complain)\n",
        "print(f\"Probability of Complain = 1 (success): {prob_success:.4f}\")\n",
        "\n",
        "# Expected value (mean) for a Bernoulli distribution\n",
        "expected_value = stats.bernoulli.mean(prob_complain)\n",
        "print(f\"Expected value (mean) for Complain: {expected_value:.4f}\")\n",
        "\n",
        "# Visualize Bernoulli distribution\n",
        "x = [0, 1]  # Possible outcomes for a Bernoulli distribution\n",
        "pmf_values = stats.bernoulli.pmf(x, prob_complain)\n",
        "\n",
        "plt.bar(x, pmf_values, align='center', alpha=0.5)\n",
        "plt.xticks(x)\n",
        "plt.xlabel('Complain')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Bernoulli Distribution for Complain')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "466f_eyFdngJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of continuous variables\n",
        "continuous_columns = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
        "\n",
        "for column in continuous_columns:\n",
        "    # Extracting data for the column (replace 'df' with your DataFrame)\n",
        "    data = df[column].dropna()  # Remove missing values if any\n",
        "\n",
        "    # Fit a Normal distribution using maximum likelihood estimation (MLE)\n",
        "    mu, sigma = stats.norm.fit(data)\n",
        "\n",
        "    # Calculate probabilities and expected value\n",
        "    prob_100 = stats.norm.cdf(100, mu, sigma)  # Probability of value <= 100\n",
        "    expected_value = stats.norm.mean(mu, sigma)  # Expected value (mean)\n",
        "\n",
        "    # Display results for each column\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(f\"Estimated Mean (mu): {mu:.2f}\")\n",
        "    print(f\"Estimated Standard Deviation (sigma): {sigma:.2f}\")\n",
        "    print(f\"Probability of value <= 100: {prob_100:.4f}\")\n",
        "    print(f\"Expected Value (mean): {expected_value:.2f}\\n\")"
      ],
      "metadata": {
        "id": "7438je4aV_vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution for products columns"
      ],
      "metadata": {
        "id": "qH88HFPts72-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=len(continuous_columns), ncols=2, figsize=(12, 8))\n",
        "\n",
        "for i, column in enumerate(continuous_columns):\n",
        "    # Extracting data for the column (replace 'df' with your DataFrame)\n",
        "    data = df[column].dropna()  # Remove missing values if any\n",
        "\n",
        "    # Fit a Normal distribution using maximum likelihood estimation (MLE)\n",
        "    mu, sigma = stats.norm.fit(data)\n",
        "\n",
        "    # Create histogram\n",
        "    axes[i, 0].hist(data, bins=30, density=True, alpha=0.6, color='blue')\n",
        "    axes[i, 0].set_title(f'Histogram for {column}')\n",
        "    axes[i, 0].set_xlabel('Value')\n",
        "    axes[i, 0].set_ylabel('Frequency')\n",
        "\n",
        "    # Create Q-Q plot (quantile-quantile plot)\n",
        "    stats.probplot(data, dist=\"norm\", plot=axes[i, 1])\n",
        "    axes[i, 1].get_lines()[1].set_color('red')  # Highlight the Normal distribution line\n",
        "    axes[i, 1].set_title(f'Q-Q plot for {column}')\n",
        "    axes[i, 1].set_xlabel('Theoretical quantiles')\n",
        "    axes[i, 1].set_ylabel('Sample quantiles')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lh39GDXxse9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of count/frequency variables\n",
        "count_columns = ['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'NumDealsPurchases']\n",
        "\n",
        "for column in count_columns:\n",
        "    # Extracting data for the column (replace 'df' with your DataFrame)\n",
        "    data = df[column].dropna()  # Remove missing values if any\n",
        "\n",
        "    # Fit a Poisson distribution using maximum likelihood estimation (MLE)\n",
        "    mu = data.mean()  # Using sample mean as parameter for Poisson\n",
        "    fitted_poisson = stats.poisson(mu)\n",
        "\n",
        "    # Calculate probabilities and expected value\n",
        "    prob_5 = fitted_poisson.pmf(5)  # Probability of value = 5\n",
        "    expected_value = fitted_poisson.mean()  # Expected value (mean)\n",
        "\n",
        "    # Display results for each column\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(f\"Estimated Mean (mu) for Poisson: {mu:.2f}\")\n",
        "    print(f\"Probability of value = 5: {prob_5:.4f}\")\n",
        "    print(f\"Expected Value (mean): {expected_value:.2f}\\n\")"
      ],
      "metadata": {
        "id": "6dkzpZ64tM9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=len(count_columns), ncols=2, figsize=(12, 8))\n",
        "\n",
        "for i, column in enumerate(count_columns):\n",
        "    # Extracting data for the column (replace 'df' with your DataFrame)\n",
        "    data = df[column].dropna()  # Remove missing values if any\n",
        "\n",
        "    # Fit a Poisson distribution using maximum likelihood estimation (MLE)\n",
        "    mu = data.mean()  # Using sample mean as parameter for Poisson\n",
        "    fitted_poisson = stats.poisson(mu)\n",
        "\n",
        "    # Create histogram\n",
        "    axes[i, 0].hist(data, bins=30, density=True, alpha=0.6, color='green')\n",
        "    axes[i, 0].set_title(f'Histogram for {column}')\n",
        "    axes[i, 0].set_xlabel('Value')\n",
        "    axes[i, 0].set_ylabel('Frequency')\n",
        "\n",
        "    # Plot the probability mass function (PMF) of the fitted Poisson distribution\n",
        "    x = range(0, int(max(data)) + 1)  # Ensure maximum value is converted to an integer\n",
        "    pmf_values = fitted_poisson.pmf(x)\n",
        "    axes[i, 1].bar(x, pmf_values, alpha=0.6, color='orange')\n",
        "    axes[i, 1].set_title(f'Poisson PMF for {column}')\n",
        "    axes[i, 1].set_xlabel('Value')\n",
        "    axes[i, 1].set_ylabel('Probability')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UC8U-iZ8tVOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 4: Insights and Customer Segmentation üìà\n",
        "\n",
        "Explore relationships between customer characteristics and spending habits. Segment customers based on their behaviors and characteristics.\n",
        "\n",
        "**Deliverables:**\n",
        "\n",
        "Key insights regarding relationships between variables and distinct customer segments based on behaviors."
      ],
      "metadata": {
        "id": "kNHOeQWKtxm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the numerical columns before calculating correlation\n",
        "numerical_dfs = dfs.select_dtypes(include=['number','float'])\n",
        "\n",
        "# Create the correlation matrix\n",
        "corr_matrix = numerical_dfs.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(20, 15))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QGmKIya_tqPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Key insights regarding variables:\n",
        "\n",
        "**1. Income and Spending Patterns:**\n",
        "\n",
        "There seems to be a positive correlation between 'Income' and spending on 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumWebPurchases', 'NumCatalogPurchases'and 'NumStorePurchases'. Higher-income customers tend to spend more on these categories.\n",
        "\n",
        "**2. 'Kidhome' and 'NumWebVisitsMonth' (correlation = 0.47):**\n",
        "\n",
        "A correlation of 0.47 indicates a moderate positive correlation between the number of children at home ('Kidhome') and the number of web visits per month ('NumWebVisitsMonth').\n",
        "This suggests that customers with more children at home are moderately more likely to make a higher number of web visits each month. The positive correlation implies that as the number of children at home increases, the number of web visits tends to increase as well.\n",
        "\n",
        "**3. 'Teenhome' and 'NumDealsPurchases':**\n",
        "\n",
        "A correlation of 0.44 between 'Teenhome' and 'NumDealsPurchases' indicates a moderate positive association, suggesting that customers with more teenagers at home tend to have a higher number of deals purchases.\n",
        "\n",
        "**4. 'NumDealsPurchases' and 'NumWebPurchases' (correlation = 0.30):**\n",
        "\n",
        "A correlation of 0.30 indicates a positive, but relatively weak, correlation between the number of deals purchases ('NumDealsPurchases') and the number of web purchases ('NumWebPurchases').\n",
        "This suggests that customers who engage in more deals purchases are somewhat more likely to make more web-based purchases. However, the correlation is not very strong, and other factors may also influence the relationship.\n",
        "\n",
        "**'NumDealsPurchases' and 'NumWebVisitsMonth' (correlation = 0.38):**\n",
        "\n",
        "A correlation of 0.38 indicates a positive, moderate correlation between the number of deals purchases ('NumDealsPurchases') and the number of web visits per month ('NumWebVisitsMonth').\n",
        "\n",
        "This suggests that customers who make a higher number of deals purchases are moderately more likely to have a higher number of web visits each month. The positive correlation implies that as the number of deals purchases increases, the number of web visits tends to increase as well."
      ],
      "metadata": {
        "id": "qS7dAIiDyv9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 5: Conclusion and Recommendations\n",
        "\n",
        "Create clear visualizations to showcase your findings. Use insights to make recommendations for the company based on your analysis."
      ],
      "metadata": {
        "id": "tZOalA9SzpNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deliverables:**\n",
        "\n",
        "Well-designed visualizations that visually represent your insights and actionable recommendations based on customer behavior analysis."
      ],
      "metadata": {
        "id": "FVkkBnLQ0I19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Targeted Marketing Campaigns:**\n",
        "\n",
        "Identify high-value customer segments and design targeted marketing campaigns to cater to their specific needs and preferences."
      ],
      "metadata": {
        "id": "HSe7fllQ0f-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average income for each marital status category\n",
        "avg_income_by_marital_status = dfs.groupby('Marital_Status')['Income'].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Marital_Status', y='Income', data=avg_income_by_marital_status, palette='viridis')\n",
        "plt.title('Average Income by Marital Status')\n",
        "plt.xlabel('Marital Status')\n",
        "plt.ylabel('Average Income')\n",
        "plt.xticks(rotation=45)  # Rotating x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b_yf6XAR0yC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['Income', 'NumDealsPurchases']\n",
        "\n",
        "# Select relevant columns\n",
        "df_selected = dfs[selected_columns]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='NumDealsPurchases', y='Income', data=df_selected, palette='viridis')\n",
        "plt.title('Distribution of Income for Customers with Deals Purchases')\n",
        "plt.xlabel('Number of Deals Purchases')\n",
        "plt.ylabel('Income')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "889mR4sGDbDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This box plot provides a more detailed view of the income distribution within different segments of customers who made varying numbers of deals purchases.\n",
        "\n",
        "These visualizations can help understand the behavior of customers responding well to deals and promotions, allowing to design targeted promotions and marketing strategies accordingly. Adjust the selected columns and explore additional variables based on your specific business context and goals."
      ],
      "metadata": {
        "id": "uMxdsvcYDlIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Website Optimization:**\n",
        "\n",
        "Focus on improving the online shopping experience, as customers making more web purchases ('NumWebPurchases') and having higher web visits ('NumWebVisitsMonth') represent an engaged online audience.\n",
        "Optimize the website for better user experience and ensure a seamless checkout process."
      ],
      "metadata": {
        "id": "AXh3FF72Dtr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['NumWebPurchases', 'NumWebVisitsMonth']\n",
        "\n",
        "# Select relevant columns\n",
        "df_selected = dfs[selected_columns]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='NumWebPurchases', y='NumWebVisitsMonth', data=df_selected, alpha=0.7, color='blue')\n",
        "sns.regplot(x='NumWebPurchases', y='NumWebVisitsMonth', data=df_selected, scatter=False, color='red')\n",
        "plt.title('Online Shopping Behavior: Web Purchases vs Web Visits')\n",
        "plt.xlabel('Number of Web Purchases')\n",
        "plt.ylabel('Number of Web Visits per Month')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AP-ibatoEXnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key insights from a downward-sloping regression line:**\n",
        "\n",
        "**Inverse Relationship:** Customers who engage in more web visits per month are making fewer web purchases. This suggests that a higher number of web visits might not necessarily translate into a higher number of transactions.\n",
        "\n",
        "**Potential Issues:** There may be potential issues or barriers on the website that hinder customers from completing transactions despite frequent visits. It could be related to the user interface, checkout process, or other aspects of the online shopping experience.\n",
        "\n",
        "In summary, a downward-sloping regression line suggests that there might be room for improvement in converting web visits into actual purchases. Analyzing the reasons behind this inverse relationship can guide website optimization efforts to create a more effective and conversion-friendly online shopping experience."
      ],
      "metadata": {
        "id": "UQzTQVf9E1V9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Segment-Specific Communication:**\n",
        "\n",
        "Craft communication strategies based on customer segments. For example, communicate differently with families having 'Kidhome' and 'Teenhome' compared to those without children."
      ],
      "metadata": {
        "id": "KGWAb8S2FsBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['Kidhome', 'Teenhome']\n",
        "\n",
        "# Select relevant columns\n",
        "df_selected = dfs[selected_columns]\n",
        "\n",
        "# Count plot for family structure\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Kidhome', data=df_selected, hue='Teenhome', palette='coolwarm')\n",
        "plt.title('Family Structure: Customers with Kidhome and Teenhome')\n",
        "plt.xlabel('Presence of Kidhome')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Presence of Teenhome', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a0323EIDzmvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights from the visualization:**\n",
        "\n",
        "**Family Structure Distribution:**\n",
        "\n",
        "The count plot displays the distribution of customers based on the presence of 'Kidhome' and 'Teenhome'.\n",
        "Different colors represent the presence or absence of 'Teenhome' within each category of 'Kidhome'.\n",
        "\n",
        "**Communication Strategy Insights:**\n",
        "\n",
        "If there are distinct segments with families having both 'Kidhome' and 'Teenhome', it indicates a unique customer segment with specific communication needs.\n",
        "By understanding the composition of your customer base in terms of family structure, you can tailor communication strategies to address the preferences and needs of different segments.\n",
        "Targeted Messaging:\n",
        "\n",
        "Consider crafting targeted messages for families with both 'Kidhome' and 'Teenhome' that resonate with their specific interests and challenges.\n",
        "Communication strategies for customers without children may focus on different aspects that align with their lifestyle and preferences.\n",
        "\n",
        "**Personalized Offers:**\n",
        "\n",
        "Use this information to personalize offers or promotions that cater to the needs of specific family segments, enhancing the effectiveness of your marketing campaigns.\n",
        "\n",
        "**5. In-Store Experience Enhancement:**\n",
        "\n",
        "Consider enhancing the in-store experience for customers who make a significant number of in-store purchases ('NumStorePurchases').\n",
        "Implement loyalty programs or exclusive in-store promotions to encourage repeat visits."
      ],
      "metadata": {
        "id": "5_vcjMsFGrnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['NumStorePurchases', 'Response']\n",
        "\n",
        "# Select relevant columns\n",
        "df_selected = dfs[selected_columns]\n",
        "\n",
        "# Count plot for in-store purchases\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x='NumStorePurchases', data=df_selected, palette='viridis')\n",
        "plt.title('Distribution of In-Store Purchases')\n",
        "plt.xlabel('Number of In-Store Purchases')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "# Bar plot for participation in loyalty programs based on in-store purchases\n",
        "loyalty_counts = df_selected.groupby('NumStorePurchases')['Response'].value_counts().unstack()\n",
        "loyalty_counts.plot(kind='bar', stacked=True, color=['lightblue', 'darkblue'], figsize=(12, 6))\n",
        "plt.title('In-Store Experience Enhancement: In-Store Purchases vs Loyalty Program Participation')\n",
        "plt.xlabel('Number of In-Store Purchases')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Response', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jN-APu_JH6Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights from the visualizations:**\n",
        "\n",
        "**In-Store Purchases Distribution:**\n",
        "\n",
        "The count plot displays the distribution of customers based on the number of in-store purchases ('NumStorePurchases').\n",
        "Identify the segments of customers who make a significant number of in-store purchases.\n",
        "\n",
        "**Effectiveness of Loyalty Programs:**\n",
        "\n",
        "The bar plot compares the participation in loyalty programs ('Response') for different levels of in-store purchases.\n",
        "If customers with a higher number of in-store purchases show a higher participation rate in loyalty programs, it indicates the effectiveness of these programs in retaining these customers.\n",
        "Opportunities for Enhancement:\n",
        "\n",
        "Focus on enhancing the in-store experience for customers who make fewer in-store purchases, as indicated by the distribution.\n",
        "Consider implementing exclusive in-store promotions, personalized offers, or loyalty programs to encourage repeat visits and purchases.\n",
        "Tailored In-Store Strategies:\n",
        "\n",
        "Tailor in-store strategies based on the insights gained from the distribution of in-store purchases. Consider factors such as product placement, customer service, and promotional activities.\n",
        "These visualizations provide insights into the distribution of in-store purchases and the effectiveness of loyalty programs, guiding efforts to enhance the in-store experience for different customer segments."
      ],
      "metadata": {
        "id": "fgbnx49AI8on"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus Task - Geogebra Experiment**\n",
        "\n",
        "Here's the link to an intriguing GeoGebra experiment: GeoGebra Experiment Link\n",
        "\n",
        "This experiment lets you simulate coin flips as per your preferences and specifications!\n",
        "\n",
        "Your task involves recording a video where you'll explain the concept of the Law of Large Numbers using this experiment. Dive further into the experience by adjusting the number of coins and exploring varying coin biases. ü™ôüìπüîç"
      ],
      "metadata": {
        "id": "cqHjXdasJb1o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5V06fjU6IaMk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}